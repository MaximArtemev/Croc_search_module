{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pymorphy2\n",
    "import re\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "AllowedWords = '[а-я]+'\n",
    "\n",
    "wordNormal = pymorphy2.MorphAnalyzer()\n",
    "stop_words = {wordNormal.normal_forms(i)[0] for i in get_stop_words('ru')}\n",
    "\n",
    "docs1 = dict()\n",
    "docs2 = dict()\n",
    "\n",
    "MODEL_NAME = 'finaleModel.bin'\n",
    "\n",
    "\n",
    "search = '''Как добавить виджет на страницу'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ToDo maybe not normal form?\n",
    "\n",
    "#ToDo use unclean docs?\n",
    "\n",
    "#ToDo ./sent2vec-master/fasttext ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanTest():\n",
    "    for num,name in enumerate(os.listdir(\"./Dirty/Data/\")):\n",
    "        with open(\"./Dirty/Data/\"+name, 'r') as doc:\n",
    "            soup = BeautifulSoup(doc.read(), 'html.parser')\n",
    "            with open(\"./Clean/Data/\"+str(num)+'.txt', 'w') as clean:\n",
    "                clean.write(' '.join(soup.getText(' ').strip().split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTestfromData():\n",
    "    text = ''\n",
    "    for name in os.listdir(\"./Clean/Data/\"):\n",
    "        try:\n",
    "            with open(\"./Clean/Data/\"+name, 'r',) as doc:\n",
    "                #docs1[name] = \"\"\n",
    "                for word in re.findall(AllowedWords, doc.read().lower()):\n",
    "                    normal = wordNormal.normal_forms(word)[0]\n",
    "                    #docs1[name] += str(normal)\n",
    "                    #docs1[name] += ' '\n",
    "                    text += str(normal) + ' '\n",
    "                text += '\\n'\n",
    "        except:\n",
    "            print(\"haha\")\n",
    "    with open('./Technical/test.txt', 'w') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def createTest():\\n    with open('./Technical/test.txt', 'w') as file:\\n        for i in docs1:\\n            file.write(docs1[i])\\n            file.write('\\n')\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def createTest():\n",
    "    with open('./Technical/test.txt', 'w') as file:\n",
    "        for i in docs1:\n",
    "            file.write(docs1[i])\n",
    "            file.write('\\n')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clearTrain():\n",
    "    for num, name in enumerate(os.listdir(\"./Dirty/Discussions/\")):\n",
    "        with open(\"./Dirty/Discussions/\"+name, 'r') as doc:\n",
    "            soup = BeautifulSoup(doc.read(), 'html.parser')\n",
    "            with open(\"./Clean/Discussions/\"+str(num)+'.txt', 'w') as clean:\n",
    "                clean.write(' '.join(soup.getText(' ').strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTrainfromDiss():\n",
    "    text = ''\n",
    "    for name in os.listdir(\"./Clean/Discussions/\"):\n",
    "        try:\n",
    "            with open(\"./Clean/Discussions/\"+name, 'r') as doc:\n",
    "                #docs[name] = \"\"\n",
    "                for word in re.findall(AllowedWords, doc.read().lower()):\n",
    "                    normal = wordNormal.normal_forms(word)[0]\n",
    "                    #docs[name] += str(normal)\n",
    "                    #docs[name] += ' '\n",
    "                    text += str(normal) + ' '\n",
    "                text += '\\n'\n",
    "        except:\n",
    "            print(\"haha\")\n",
    "    with open('./Technical/train.txt', 'w') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def createTrain():\\n    with open('./Technical/ttest.txt', 'w') as file:\\n        for i in docs:\\n            file.write(' '.join(docs[i].strip().split()))\\n            file.write('\\n')\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def createTrain():\n",
    "    with open('./Technical/ttest.txt', 'w') as file:\n",
    "        for i in docs:\n",
    "            file.write(' '.join(docs[i].strip().split()))\n",
    "            file.write('\\n')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanTest()\n",
    "clearTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "createTrainfromDiss()\n",
    "createTestfromData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def trainModel():\n",
    "command = \"\"\"./sent2vec/fasttext sent2vec -input \\\n",
    "    ./Technical/train.txt -output ./Model/{} -minCount 2 -dim 700\\\n",
    "        -epoch 9 -lr 0.15 -wordNgrams 2 -loss ns -neg 10 -thread 2\\\n",
    "            -t 0.000005 -dropoutK 4 -minCountLabel 10\"\"\".format(MODEL_NAME)\n",
    "os.system(command)\n",
    "#ToDo mb os.popen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def getDocsVectors():\n",
    "command = \"\"\"./sent2vec/fasttext print-sentence-vectors ./Model/{} < ./Technical/test.txt\"\"\".format(MODEL_NAME)\n",
    "output = os.popen(command).readlines()\n",
    "#answer = [i for i in output.strip().split('\\n')] #ToDo mb abother split?\n",
    "# This is N-ish vector ['1,2,3,4,4,5', '12,4,5,5,5,5,5', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def ClearVectors():\n",
    "clearVec = dict()\n",
    "with open('./Technical/test.txt', 'r') as test:\n",
    "    text = test.readlines()\n",
    "    for num, i in enumerate(output):\n",
    "        clearVec[(text[num].strip())] = [float(j) for j in i.strip().split()]\n",
    "        #dict like {'text': 'srting-list vector ['1,3,4,5,6,6']} <- first\n",
    "        #dict like {'text': [1,2,3,4,5,7,8,]} <- now\n",
    "\n",
    "#ToDo mb return empty dict/set/list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def getGoodSearch(search):\n",
    "goodSearch = ''\n",
    "search = ' '.join(search.split()).lower()\n",
    "for word in re.findall(AllowedWords, search):\n",
    "    goodSearch += str(word) + ' '\n",
    "    #ToDo is it necessary?\n",
    "    normal = wordNormal.normal_forms(word)[0]\n",
    "    #ToDo mb put 2 normal forms? [0] and [1]??\n",
    "    if normal not in stop_words:\n",
    "        #ToDo stop words??\n",
    "        goodSearch += str(normal) + ' '\n",
    "with open('./Technical/input.txt', 'w') as inp:\n",
    "    inp.write(goodSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ToDo mb put in not in file but in console text itself?\n",
    "\n",
    "#def makeSearch(search):\n",
    "command = \"\"\"./sent2vec/fasttext print-sentence-vectors ./Model/{} < ./Technical/input.txt\"\"\".format(MODEL_NAME)\n",
    "asearch = os.popen(command).read()\n",
    "searchVec = [float(i) for i in asearch.strip().split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def findClosest(clearVec, searchVec):\n",
    "results = dict()\n",
    "for num, i in enumerate(clearVec):\n",
    "    if i == '':\n",
    "        continue\n",
    "    results[num] = 1 - cosine(clearVec[i], searchVec)\n",
    "sortedResults = sorted(results, key=lambda x: results[x], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.30481501575310821, 1: 0.20738449401264059, 2: 0.12266420284670743, 3: -0.054052494291593867, 4: 0.12096538319444661, 5: 0.082486299328789703, 6: 0.02654543170229573, 7: 0.10365444136872759, 8: 0.13000318416672907, 9: 0.075630270677989553, 10: 0.076748639069064817, 11: -0.030492336530628883, 12: 0.042202440057955148, 13: 0.11088984710211658, 14: 0.12354955945355484, 15: 0.028003580979760856, 16: -0.021523869161895304, 17: 0.061988044710401979, 18: 0.10410834224897303, 19: 0.095763569930699788, 20: 0.13411265555987328, 21: 0.095095189403131664, 22: 0.062978945587391477, 23: 0.039993723073082688, 24: 0.031559117317904173, 25: 0.087686951720215012, 26: 0.040350318143373198, 27: 0.061308948383725692, 28: 0.10484961032997775, 29: 0.046753103972888899, 30: 0.09900457659286821, 31: 0.12764243091732275, 32: 0.13372631847315786, 33: 0.039818325546947086, 34: 0.14813834370491419, 35: 0.099640640871473396, 36: 0.14607135623361989, 37: 0.13569079949432461, 38: 0.086455002115053192, 39: 0.10948364181261172, 40: 0.018276812119712771, 41: 0.1278225819264287, 42: 0.093258609723023467, 43: 0.18733352728254438, 44: 0.059615814346801965, 45: 0.081884489655846271, 46: 0.015104933586549629, 47: 0.11209145918005792, 48: 0.042606267023812316, 49: 0.065850271731870635, 50: 0.046806165967948288, 51: 0.035700363165831916, 52: 0.024405096780791169, 53: 0.056937818093965253, 54: 0.059305338933550722, 55: 0.16604230560979949, 56: 0.2395893517805503, 57: 0.074949181781787444, 58: 0.13748510474845244, 59: 0.090553068112047108, 60: 0.0040368340563153859, 61: 0.083507829645309894, 62: 0.18387528830376987, 63: 0.11578893757967068, 65: -0.041011572417956277, 66: 0.09583108140360852, 67: 0.15039807001413075, 68: 0.0616720430581299, 69: 0.13351225793082566, 70: 0.13158061294060408, 71: 0.11990382397850563, 72: 0.1182750529480453, 73: 0.12976552195868718, 74: 0.10037372999527805, 75: 0.141139099081806, 76: 0.19491509517827466}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 56,\n",
       " 1,\n",
       " 76,\n",
       " 43,\n",
       " 62,\n",
       " 55,\n",
       " 67,\n",
       " 34,\n",
       " 36,\n",
       " 75,\n",
       " 58,\n",
       " 37,\n",
       " 20,\n",
       " 32,\n",
       " 69,\n",
       " 70,\n",
       " 8,\n",
       " 73,\n",
       " 41,\n",
       " 31,\n",
       " 14,\n",
       " 2,\n",
       " 4,\n",
       " 71,\n",
       " 72,\n",
       " 63,\n",
       " 47,\n",
       " 13,\n",
       " 39,\n",
       " 28,\n",
       " 18,\n",
       " 7,\n",
       " 74,\n",
       " 35,\n",
       " 30,\n",
       " 66,\n",
       " 19,\n",
       " 21,\n",
       " 42,\n",
       " 59,\n",
       " 25,\n",
       " 38,\n",
       " 61,\n",
       " 5,\n",
       " 45,\n",
       " 10,\n",
       " 9,\n",
       " 57,\n",
       " 49,\n",
       " 22,\n",
       " 17,\n",
       " 68,\n",
       " 27,\n",
       " 44,\n",
       " 54,\n",
       " 53,\n",
       " 50,\n",
       " 29,\n",
       " 48,\n",
       " 12,\n",
       " 26,\n",
       " 23,\n",
       " 33,\n",
       " 51,\n",
       " 24,\n",
       " 15,\n",
       " 6,\n",
       " 52,\n",
       " 40,\n",
       " 46,\n",
       " 60,\n",
       " 16,\n",
       " 11,\n",
       " 65,\n",
       " 3]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
